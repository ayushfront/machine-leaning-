{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO9DIPxYvLSlGFAhEBYCuwo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"cNKBBqQzxxCy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Text Emotions Classification using Python"],"metadata":{"id":"fvtMo_Wex29k"}},{"cell_type":"markdown","source":["Text emotions classification is the problem of assigning emotion to a text by understanding the context and the emotion behind the text. One real-world example is the keyboard of an iPhone that recommends the most relevant emoji by understanding the text. So, if you want to learn how to classify the emotions of a text, this article is for you. In this article, I will take you through the task of text emotions classification with Machine Learning using Python.\n","\n"],"metadata":{"id":"PQBuql64x7lO"}},{"cell_type":"markdown","source":["# **Text Emotions Classification**\n","Text emotions classification is the problem of natural language processing and text classification. Here we need to train a text classification model to classify the emotion of a text.\n","\n","To solve this problem, we need labelled data of texts and their emotions. I found an ideal dataset to solve this problem on Kaggle. You can download the dataset from here.\n","\n","In the section below, I’ll take you through how to train a text classification model for the task of Text Emotions Classification using Machine Learning and the Python programming language."],"metadata":{"id":"qboQyo8DyCt_"}},{"cell_type":"markdown","source":["# **Text Emotions Classification using Python**"],"metadata":{"id":"8agPO3bAyGn_"}},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"975PuiJunzNp","executionInfo":{"status":"ok","timestamp":1720633885033,"user_tz":-330,"elapsed":626,"user":{"displayName":"Ayush Pal","userId":"10098169209514968740"}},"outputId":"de74fe91-bff4-477b-9a1d-4ee1a1e52e23"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                Text Emotions\n","0  i can go from feeling so hopeless to so damned...  sadness\n","1   im grabbing a minute to post i feel greedy wrong    anger\n","2  i am ever feeling nostalgic about the fireplac...     love\n","3                               i am feeling grouchy    anger\n","4  ive been feeling a little burdened lately wasn...  sadness\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import keras\n","import tensorflow\n","from keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from keras.layers import Embedding, Flatten, Dense\n","\n","\n","data =pd.read_csv(\"/content/train.txt\", sep=';')\n","data.columns = ['Text', 'Emotions']\n","print(data.head())\n"]},{"cell_type":"markdown","source":["As this is a problem of natural language processing, I’ll start by tokenizing the data:"],"metadata":{"id":"LQjkjo6WyLy4"}},{"cell_type":"code","source":["text = data['Text'].tolist()\n","labels  = data['Emotions'].tolist()\n","\n","# Tokenize the text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(text)"],"metadata":{"id":"k0VYgcB-qYZb","executionInfo":{"status":"ok","timestamp":1720632842910,"user_tz":-330,"elapsed":789,"user":{"displayName":"Ayush Pal","userId":"10098169209514968740"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Now we need to pad the sequences to the same length to feed them into a neural network. Here’s how we can pad the sequences of the texts to have the same length:"],"metadata":{"id":"8B8aLE64yYvd"}},{"cell_type":"code","source":["sequences = tokenizer.texts_to_sequences(text)\n","max_length = max(len(seq) for seq in sequences)\n","padded_sequences = pad_sequences(sequences, maxlen=max_length)"],"metadata":{"id":"j8mDsrYurMk5","executionInfo":{"status":"ok","timestamp":1720632856333,"user_tz":-330,"elapsed":567,"user":{"displayName":"Ayush Pal","userId":"10098169209514968740"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["Now I’ll use the label encoder method to convert the classes from strings to a numerical representation:"],"metadata":{"id":"ezAJPARiycdG"}},{"cell_type":"code","source":["# Encode the string labels to integers\n","lower_encoder = LabelEncoder()\n","lables = lower_encoder.fit_transform(labels)\n"],"metadata":{"id":"wa_xjbuXrd3W","executionInfo":{"status":"ok","timestamp":1720632858682,"user_tz":-330,"elapsed":4,"user":{"displayName":"Ayush Pal","userId":"10098169209514968740"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["We are now going to One-hot encode the labels. One hot encoding refers to the transformation of categorical labels into a binary representation where each label is represented as a vector of all zeros except a single 1. This is necessary because machine learning algorithms work with numerical data. So here is how we can One-hot encode the labels:"],"metadata":{"id":"kr4UjTdvygco"}},{"cell_type":"code","source":["# One-hot encode the labels\n","one_hot_lables = keras.utils.to_categorical(lables)\n"],"metadata":{"id":"TRfkPB6PrqlN","executionInfo":{"status":"ok","timestamp":1720632862131,"user_tz":-330,"elapsed":704,"user":{"displayName":"Ayush Pal","userId":"10098169209514968740"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# Text Emotions Classification Model"],"metadata":{"id":"MY0QIZkCr0Jt"}},{"cell_type":"code","source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, one_hot_lables, test_size=0.2)"],"metadata":{"id":"eoa4L_fLr3nV","executionInfo":{"status":"ok","timestamp":1720632866154,"user_tz":-330,"elapsed":2,"user":{"displayName":"Ayush Pal","userId":"10098169209514968740"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["Now let’s define a neural network architecture for our classification problem and use it to train a model to classify emotions:"],"metadata":{"id":"JVYFAAJ_sBWm"}},{"cell_type":"code","source":["# Define the model\n","model = Sequential()\n","model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length))\n","\n","model.add(Flatten())\n","model.add(Dense(units=128, activation='relu'))\n","model.add(Dense(units= len(one_hot_lables[0]), activation='softmax'))\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MISaXzR8sDyP","executionInfo":{"status":"ok","timestamp":1720633062973,"user_tz":-330,"elapsed":173161,"user":{"displayName":"Ayush Pal","userId":"10098169209514968740"}},"outputId":"3cff14af-a50c-41ab-9e33-a9745d75bf02"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","400/400 [==============================] - 18s 44ms/step - loss: 1.4104 - accuracy: 0.4596 - val_loss: 0.9851 - val_accuracy: 0.6491\n","Epoch 2/10\n","400/400 [==============================] - 21s 51ms/step - loss: 0.4195 - accuracy: 0.8687 - val_loss: 0.5328 - val_accuracy: 0.8150\n","Epoch 3/10\n","400/400 [==============================] - 17s 44ms/step - loss: 0.0712 - accuracy: 0.9814 - val_loss: 0.5469 - val_accuracy: 0.8247\n","Epoch 4/10\n","400/400 [==============================] - 17s 42ms/step - loss: 0.0284 - accuracy: 0.9940 - val_loss: 0.5511 - val_accuracy: 0.8366\n","Epoch 5/10\n","400/400 [==============================] - 15s 39ms/step - loss: 0.0194 - accuracy: 0.9958 - val_loss: 0.5697 - val_accuracy: 0.8347\n","Epoch 6/10\n","400/400 [==============================] - 17s 43ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.6560 - val_accuracy: 0.8247\n","Epoch 7/10\n","400/400 [==============================] - 16s 41ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.6395 - val_accuracy: 0.8309\n","Epoch 8/10\n","400/400 [==============================] - 17s 42ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.6803 - val_accuracy: 0.8247\n","Epoch 9/10\n","400/400 [==============================] - 19s 49ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.7335 - val_accuracy: 0.8216\n","Epoch 10/10\n","400/400 [==============================] - 14s 35ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.6527 - val_accuracy: 0.8253\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ebdeeb09270>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["input_text = \"She didn't come today because she lost her dog yestertay!\"\n","# Preprocess the input text\n","input_sequences = tokenizer.texts_to_sequences([input_text])\n","padded_input_sequence  = pad_sequences(input_sequences, maxlen=max_length)\n","predection = model.predict(padded_input_sequence)\n","\n","\n","label_encoder = LabelEncoder()\n","label_encoder.fit(labels)\n","\n","\n","\n","predicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\n","print(predicted_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jP_OfFaBto0H","executionInfo":{"status":"ok","timestamp":1720633926648,"user_tz":-330,"elapsed":528,"user":{"displayName":"Ayush Pal","userId":"10098169209514968740"}},"outputId":"17d83fe5-bb2d-426b-c650-12390d1ab07a"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","['sadness']\n"]}]},{"cell_type":"markdown","source":["# **Summary**\n","Text emotion classification is the problem of assigning emotion to a text by understanding the context and the emotion behind the text. One real-world example is the keyboard of an iPhone that recommends the most relevant emoji by understanding the text. I hope you liked this article on Text Emotion Classification with Machine Learning using Python. Feel free to ask valuable questions in the comments section below."],"metadata":{"id":"hsbTDKGbylZQ"}}]}